\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\BKM@entry[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\BKM@entry{id=1,open,dest={446F632D5374617274},srcline={20}}{20434F4E54454E5453205C303430}
\@writefile{toc}{\contentsline {part}{ \bf  {\contentsnameToC } }{iii}{Doc-Start}}
\BKM@entry{id=2,open,dest={73656374696F6E2E31},srcline={23}}{494E54524F44554354494F4E}
\citation{rencao11}
\citation{glavic06}
\citation{clement04}
\citation{stone00}
\citation{stone00}
\citation{tomlin98}
\citation{swaminathan98}
\citation{glavic06}
\@writefile{toc}{\contentsline {section}{\numberline {1}INTRODUCTION}{1}{section.1}}
\citation{silver2016mastering}
\citation{zhang2016learning}
\citation{mnih-dqn-2015}
\citation{redding2011approximate}
\citation{hausknecht2015deep}
\citation{tampuu2017multiagent}
\citation{amato13}
\citation{chen2016decentralized}
\BKM@entry{id=3,open,dest={73656374696F6E2E32},srcline={41}}{54494D4520504C414E2050524553454E54454420494E205448455349532050524F504F53414C}
\BKM@entry{id=4,open,dest={73656374696F6E2E33},srcline={57}}{434F4E545249425554494F4E204F4620544845205354554449455320434F4E44554354454420445552494E4720544845204C41535420534958204D4F4E5448532057495448494E205448452057484F4C4520544845534953205354554459}
\@writefile{toc}{\contentsline {section}{\numberline {2}TIME PLAN PRESENTED IN THESIS PROPOSAL}{3}{section.2}}
\@writefile{toc}{\contentsline {section}{\numberline {3}CONTRIBUTION OF THE STUDIES CONDUCTED DURING THE LAST SIX MONTHS WITHIN THE WHOLE THESIS STUDY}{3}{section.3}}
\BKM@entry{id=5,open,dest={73656374696F6E2E34},srcline={61}}{4558504C414E4154494F4E204F4620544845205354554449455320434F4E44554354454420445552494E4720544845204C41535420534958204D4F4E54485320494E204143434F5244414E43452057495448205448452054494D4520504C414E20414E4420544845495220524553554C5453}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Time plan presented in thesis proposal. \relax }}{4}{figure.caption.1}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:timeplan}{{1}{4}{Time plan presented in thesis proposal. \relax }{figure.caption.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4}EXPLANATION OF THE STUDIES CONDUCTED DURING THE LAST SIX MONTHS IN ACCORDANCE WITH THE TIME PLAN AND THEIR RESULTS}{4}{section.4}}
\newlabel{sec:literature}{{4}{4}{EXPLANATION OF THE STUDIES CONDUCTED DURING THE LAST SIX MONTHS IN ACCORDANCE WITH THE TIME PLAN AND THEIR RESULTS}{section.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Benchmark Problems}{4}{subsection.4.1}}
\newlabel{sec:benchmarkproblems}{{4.1}{4}{Benchmark Problems}{subsection.4.1}{}}
\@writefile{toc}{\contentsline {subsubsection}{Blocks World Planning Problem}{5}{section*.2}}
\newlabel{sec:blocksworldproblem}{{4.1}{5}{Blocks World Planning Problem}{section*.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Blocks world domain is a planning problem that consists a set of blocks and slots. \relax }}{5}{figure.caption.3}}
\newlabel{fig:blocksworld}{{2}{5}{Blocks world domain is a planning problem that consists a set of blocks and slots. \relax }{figure.caption.3}{}}
\citation{irodova2005reinforcement}
\citation{kochenderfer2015decision}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Blocks world domain suffers from curse of dimensionality. \relax }}{6}{figure.caption.4}}
\newlabel{fig:blocksworld_curseofdimensionality}{{3}{6}{Blocks world domain suffers from curse of dimensionality. \relax }{figure.caption.4}{}}
\@writefile{toc}{\contentsline {subsubsection}{Grid World Planning Problem}{6}{section*.5}}
\newlabel{sec:gridworldproblem}{{4.1}{6}{Grid World Planning Problem}{section*.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Grid world is one of the most used problem in reinforcement learning. \relax }}{7}{figure.caption.6}}
\newlabel{fig:gridworld}{{4}{7}{Grid world is one of the most used problem in reinforcement learning. \relax }{figure.caption.6}{}}
\@writefile{toc}{\contentsline {subsubsection}{Rendezvous Planning Problem}{7}{section*.7}}
\newlabel{sec:rendezvousproblem}{{4.1}{7}{Rendezvous Planning Problem}{section*.7}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Rendezvous planning problem is derived from grid world to evaluate multi-agent scenarios. \relax }}{7}{figure.caption.8}}
\newlabel{fig:rendezvous}{{5}{7}{Rendezvous planning problem is derived from grid world to evaluate multi-agent scenarios. \relax }{figure.caption.8}{}}
\citation{kochenderfer2015decision}
\citation{puterman2014markov}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Overview Of Planning Framework}{8}{subsection.4.2}}
\newlabel{sec:overviewofplanningframework}{{4.2}{8}{Overview Of Planning Framework}{subsection.4.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Multilevel inheritance of multi-agent reinforcement learning framework. \relax }}{8}{figure.caption.9}}
\newlabel{fig:inheritgraphcombined_1}{{6}{8}{Multilevel inheritance of multi-agent reinforcement learning framework. \relax }{figure.caption.9}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Class diagram of developed framework. \relax }}{9}{figure.caption.10}}
\newlabel{fig:inheritgraphcombined}{{7}{9}{Class diagram of developed framework. \relax }{figure.caption.10}{}}
\citation{toksoz2012design}
\citation{boutilier1999sequential}
\citation{amato13}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Markov Decision Processes (MDPs)}{10}{subsection.4.3}}
\newlabel{sec:mdp}{{4.3}{10}{Markov Decision Processes (MDPs)}{subsection.4.3}{}}
\newlabel{eq:mdptuple}{{4.1}{10}{Markov Decision Processes (MDPs)}{equation.4.1}{}}
\newlabel{eq:cumdiscreward}{{4.2}{10}{Markov Decision Processes (MDPs)}{equation.4.2}{}}
\citation{proper2009solving}
\citation{boutilier1999decision}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4}Multiagent Markov Decision Processes (MMDPs)}{11}{subsection.4.4}}
\newlabel{sec:mmdp}{{4.4}{11}{Multiagent Markov Decision Processes (MMDPs)}{subsection.4.4}{}}
\newlabel{eq:mmdptuple}{{4.3}{11}{Multiagent Markov Decision Processes (MMDPs)}{equation.4.3}{}}
\newlabel{eq:factorizedactions}{{4.4}{11}{Multiagent Markov Decision Processes (MMDPs)}{equation.4.4}{}}
\newlabel{eq:factorizedstates}{{4.5}{11}{Multiagent Markov Decision Processes (MMDPs)}{equation.4.5}{}}
\newlabel{eq:factorizedtransition}{{4.6}{11}{Multiagent Markov Decision Processes (MMDPs)}{equation.4.6}{}}
\newlabel{eq:factorizedreward}{{4.7}{11}{Multiagent Markov Decision Processes (MMDPs)}{equation.4.7}{}}
\citation{bellman1958dynamic}
\citation{sutton1984temporal}
\citation{busoni:1}
\citation{bertsekas:1}
\citation{bertsekas:1}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5}Planning with MDPs}{12}{subsection.4.5}}
\newlabel{sec:planningwithmdps}{{4.5}{12}{Planning with MDPs}{subsection.4.5}{}}
\newlabel{eq:cumdiscreward}{{4.8}{12}{Planning with MDPs}{equation.4.8}{}}
\newlabel{eq:bellmanQ}{{4.9}{12}{Planning with MDPs}{equation.4.9}{}}
\newlabel{eq:optimalpolicy}{{4.10}{12}{Planning with MDPs}{equation.4.10}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.6}Dynamic Programming }{12}{subsection.4.6}}
\citation{zhou2015trajectory}
\citation{geramifard:1}
\newlabel{eq:bellmanQ}{{4.11}{13}{Dynamic Programming}{equation.4.11}{}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {1}{\ignorespaces Q-Value Iteration\relax }}{13}{algorithm.1}}
\newlabel{alg:value-iteration}{{1}{13}{Q-Value Iteration\relax }{algorithm.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Single agent grid world simulation with tabular q-value iteration. \relax }}{13}{figure.caption.11}}
\newlabel{fig:tabularsingleagent}{{8}{13}{Single agent grid world simulation with tabular q-value iteration. \relax }{figure.caption.11}{}}
\citation{geramifard:1}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.7}Trajectory Based Value Iteration }{14}{subsection.4.7}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {2}{\ignorespaces Trajectory Based Value Iteration\relax }}{14}{algorithm.2}}
\newlabel{alg:tbvi}{{2}{14}{Trajectory Based Value Iteration\relax }{algorithm.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.8}Representations}{14}{subsection.4.8}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Single agent grid world simulation with tabular trajectory based q-value iteration. \relax }}{15}{figure.caption.12}}
\newlabel{fig:trajectorysingleagent}{{9}{15}{Single agent grid world simulation with tabular trajectory based q-value iteration. \relax }{figure.caption.12}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.9}Deep Network}{15}{subsection.4.9}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.10}Training with Backpropagation}{15}{subsection.4.10}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces An example of network structure for 4x3 Gridworld with single hidden layer. \relax }}{16}{figure.caption.13}}
\newlabel{fig:networkstructure}{{10}{16}{An example of network structure for 4x3 Gridworld with single hidden layer. \relax }{figure.caption.13}{}}
\citation{mnih-dqn-2015}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.11}Batch Training}{17}{subsection.4.11}}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces Stochastic and batch optimization. \relax }}{17}{figure.caption.14}}
\newlabel{fig:batchdata}{{11}{17}{Stochastic and batch optimization. \relax }{figure.caption.14}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.12}Experience Replay}{17}{subsection.4.12}}
\citation{mnih-dqn-2015}
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces Batch learning comparison with different hyperparameters. \relax }}{18}{figure.caption.15}}
\newlabel{fig:batchcomparison}{{12}{18}{Batch learning comparison with different hyperparameters. \relax }{figure.caption.15}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.13}Deep-Q-Networks Structure}{18}{subsection.4.13}}
\newlabel{sec:TODO!PAR}{{4.13}{18}{Deep-Q-Networks Structure}{subsection.4.13}{}}
\citation{schaul2015prioritized}
\citation{andrychowicz2017hindsight}
\citation{kaelbling1996reinforcement}
\@writefile{lof}{\contentsline {figure}{\numberline {13}{\ignorespaces Multiagent simulation with deep network. \relax }}{19}{figure.caption.16}}
\newlabel{fig:deepmultiagent}{{13}{19}{Multiagent simulation with deep network. \relax }{figure.caption.16}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {14}{\ignorespaces Multiagent simulation with smaller network. \relax }}{19}{figure.caption.17}}
\newlabel{fig:deepmultiagent2}{{14}{19}{Multiagent simulation with smaller network. \relax }{figure.caption.17}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.14}Prioritized Experience Replay}{19}{subsection.4.14}}
\citation{schaul2015prioritized}
\@writefile{lof}{\contentsline {figure}{\numberline {15}{\ignorespaces Sum-Tree data structure is utilized by prioritized experience replay. \relax }}{20}{figure.caption.18}}
\newlabel{fig:sumtree}{{15}{20}{Sum-Tree data structure is utilized by prioritized experience replay. \relax }{figure.caption.18}{}}
\BKM@entry{id=6,open,dest={73656374696F6E2E35},srcline={474}}{5354554449455320445552494E4720544845204C41535420534958204D4F4E54485320494E434C5544454420494E2054494D4520504C414E20425554204E4F5420434F4E44554354454420414E4420524541534F4E53}
\@writefile{lof}{\contentsline {figure}{\numberline {16}{\ignorespaces Simulations with different alpha parameters of prioritized experience replay. \relax }}{21}{figure.caption.19}}
\newlabel{fig:prioritizeder3}{{16}{21}{Simulations with different alpha parameters of prioritized experience replay. \relax }{figure.caption.19}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.15}Comparison of Uniform vs Prioritized Experience Replays}{21}{subsection.4.15}}
\@writefile{lof}{\contentsline {figure}{\numberline {17}{\ignorespaces Comparison of Uniform vs Prioritized Experience Replays. \relax }}{21}{figure.caption.20}}
\newlabel{fig:prioritizeder2}{{17}{21}{Comparison of Uniform vs Prioritized Experience Replays. \relax }{figure.caption.20}{}}
\BKM@entry{id=7,open,dest={73656374696F6E2E36},srcline={477}}{4348414E47455320494E20544845204D4554484F444F4C4F475920414E4420544845495220524541534F4E53}
\BKM@entry{id=8,open,dest={73656374696F6E2E37},srcline={480}}{4558504C414E4154494F4E204F4620544845205354554449455320504C414E4E454420464F5220544845204E45585420534958204D4F4E544853}
\citation{li2017deep}
\citation{gupta2017cooperative}
\BKM@entry{id=9,open,dest={73656374696F6E2E38},srcline={493}}{5055424C49434154494F4E532041424F55542054484520544845534953205355424A454354204245494E4720505245504152454420414E442F4F52205355424D4954544544}
\@writefile{toc}{\contentsline {section}{\numberline {5}STUDIES DURING THE LAST SIX MONTHS INCLUDED IN TIME PLAN BUT NOT CONDUCTED AND REASONS}{22}{section.5}}
\@writefile{toc}{\contentsline {section}{\numberline {6}CHANGES IN THE METHODOLOGY AND THEIR REASONS}{22}{section.6}}
\@writefile{toc}{\contentsline {section}{\numberline {7}EXPLANATION OF THE STUDIES PLANNED FOR THE NEXT SIX MONTHS}{22}{section.7}}
\@writefile{lof}{\contentsline {figure}{\numberline {18}{\ignorespaces Convolutional networks and policy gradient are planned to be utilized in next six months for multiagent planning. \relax }}{23}{figure.caption.21}}
\newlabel{fig:convpolicygradient}{{18}{23}{Convolutional networks and policy gradient are planned to be utilized in next six months for multiagent planning. \relax }{figure.caption.21}{}}
\@writefile{toc}{\contentsline {section}{\numberline {8}PUBLICATIONS ABOUT THE THESIS SUBJECT BEING PREPARED AND/OR SUBMITTED}{23}{section.8}}
\bibstyle{ieeetr}
\bibdata{references}
\bibcite{rencao11}{1}
\bibcite{glavic06}{2}
\bibcite{clement04}{3}
\bibcite{stone00}{4}
\bibcite{tomlin98}{5}
\bibcite{swaminathan98}{6}
\bibcite{silver2016mastering}{7}
\bibcite{zhang2016learning}{8}
\bibcite{mnih-dqn-2015}{9}
\bibcite{redding2011approximate}{10}
\bibcite{hausknecht2015deep}{11}
\bibcite{tampuu2017multiagent}{12}
\bibcite{amato13}{13}
\bibcite{chen2016decentralized}{14}
\bibcite{irodova2005reinforcement}{15}
\bibcite{kochenderfer2015decision}{16}
\bibcite{puterman2014markov}{17}
\bibcite{toksoz2012design}{18}
\bibcite{boutilier1999sequential}{19}
\bibcite{proper2009solving}{20}
\bibcite{boutilier1999decision}{21}
\bibcite{bellman1958dynamic}{22}
\bibcite{sutton1984temporal}{23}
\bibcite{busoni:1}{24}
\bibcite{bertsekas:1}{25}
\bibcite{zhou2015trajectory}{26}
\bibcite{geramifard:1}{27}
\bibcite{schaul2015prioritized}{28}
\bibcite{andrychowicz2017hindsight}{29}
\bibcite{kaelbling1996reinforcement}{30}
\bibcite{li2017deep}{31}
\bibcite{gupta2017cooperative}{32}
